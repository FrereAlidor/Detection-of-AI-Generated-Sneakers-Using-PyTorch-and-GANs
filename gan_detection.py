# -*- coding: utf-8 -*-
"""GAN_detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dT-zKFMy0Kt7wxznX-JaiW5DDPVJPC8m

# **Détection de Sneakers Générées par IA à l'aide de PyTorch et GAN**

Ce projet se concentre spécifiquement sur les images de chaussures de marques populaires telles que Nike, Adidas et Converse. Le jeu de données utilisé dans cette étude comprend un mélange d'images réelles obtenues à partir de Google Images et d'images générées par IA produites par MidJourney, offrant un défi unique dans le domaine de la vision par ordinateur et de l'apprentissage automatique. De plus, ce projet intègre l'utilisation de **Generative Adversarial Networks (GAN)** pour générer des images de chaussures synthétiques, ce qui permet d'enrichir le jeu de données et de tester la robustesse des modèles de détection.

Ce jeu de données a été soigneusement compilé à partir de trois ensembles de données distincts disponibles sur Kaggle, fournissant une base solide pour l'entraînement de réseaux de neurones convolutifs (CNN). L'objectif est de distinguer avec précision les images de chaussures générées par IA des images réelles, en exploitant les différences subtiles qui peuvent exister entre ces deux types d'images. Le jeu de données est structuré en deux catégories principales :

- **Images Réelles** : Ces images authentiques, provenant de Google Images, présentent une variété de designs de chaussures des marques Nike, Adidas et Converse. Cette partie du jeu de données est destinée à représenter la "vérité terrain" dans nos tâches de classification.

- **Images Générées par IA** : Cette catégorie comprend des images synthétiquement créées à l'aide de la plateforme IA MidJourney, ainsi que des images générées par un **GAN** (Generative Adversarial Network). Ces images imitent les styles et les détails des chaussures réelles, mais peuvent inclure des imperfections subtiles ou des éléments stylistiques typiques du contenu généré par IA.

Les deux catégories d'images sont standardisées à une résolution de 240x240 pixels. Les images générées par IA ont été compressées et redimensionnées pour correspondre aux dimensions des images réelles, garantissant ainsi une cohérence dans les données d'entrée pour l'entraînement du modèle. Pour ceux qui souhaitent analyser les images en pleine résolution, des références aux jeux de données originaux sont fournies ci-dessous.

---

### **Utilisation des GAN dans ce projet**

Les **Generative Adversarial Networks (GAN)** jouent un rôle clé dans ce projet. Un GAN est composé de deux réseaux de neurones : un **générateur** et un **discriminateur**, qui s'affrontent dans un processus compétitif. Le générateur crée des images synthétiques à partir de bruit aléatoire, tandis que le discriminateur essaie de distinguer les images réelles des images générées. Ce processus permet au générateur d'améliorer progressivement la qualité des images qu'il produit.

Dans ce projet, le GAN est utilisé pour :
1. **Générer des images de chaussures synthétiques** : Ces images sont ajoutées au jeu de données pour enrichir la diversité des exemples d'entraînement.
2. **Tester la robustesse du modèle de détection** : En utilisant des images générées par le GAN, nous pouvons évaluer la capacité du modèle à distinguer les images réelles des images synthétiques, même lorsque celles-ci sont très réalistes.

---

# **Chargement des données et préparation**
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset, random_split
from torchvision import datasets
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import os
os.environ['CUDA_LAUNCH_BLOCKING'] = "1"
from google.colab import drive
drive.mount('/content/drive')
# Installer kagglehub si ce n'est pas déjà fait
!pip install kagglehub --quiet

# Importer les bibliothèques nécessaires
import kagglehub
import torch
import torchvision.transforms as transforms
from torchvision import datasets
from torch.utils.data import DataLoader, random_split

# Télécharger directement le dataset depuis Kaggle
dataset_path = kagglehub.dataset_download('sunnykakar/shoes-dataset-real-and-ai-generated-images')

# Définir les transformations des images
transform = transforms.Compose([
    transforms.ToTensor(),  # Convertir les images en tenseurs PyTorch
])

# Charger le dataset dans PyTorch
dataset = datasets.ImageFolder(root=dataset_path, transform=transform)

# Vérifier la taille totale du dataset
total_size = len(dataset)
train_size = int(0.6 * total_size)
val_size = int(0.2 * total_size)
test_size = total_size - train_size - val_size  # Ajustement pour éviter les erreurs

# Diviser en train/val/test
train_dataset, remaining_dataset = random_split(dataset, [train_size, total_size - train_size])
val_dataset, test_dataset = random_split(remaining_dataset, [val_size, test_size])

# Créer les DataLoaders
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# Vérifier que tout est bien chargé
print(f" Dataset chargé avec succès depuis KaggleHub !")
print(f"Train : {len(train_dataset)} images, Validation : {len(val_dataset)} images, Test : {len(test_dataset)} images")

"""## **Vérification des DataLoaders**"""

batch_size = 32

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

print(f"Training batches: {len(train_loader)}")
print(f"Validation batches: {len(val_loader)}")
print(f"Testing batches: {len(test_loader)}")
for X, y in train_loader:
    print("Training batch - X shape:", X.shape, "Y shape:", y.shape)
    break  # Just checking one batch to see if it loads correctly

for X, y in val_loader:
    print("Validation batch - X shape:", X.shape, "Y shape:", y.shape)
    break  # Checking one validation batch

for X, y in test_loader:
    print("Testing batch - X shape:", X.shape, "Y shape:", y.shape)
    break  # Similarly, checking one test batch

"""## **Dictionnaire des classes**"""

class_dict = {
    0: "AI",
    1: "Real"
}

batch = next(iter(train_loader))
images, labels = batch
images = images.numpy()

"""# **Visualisation des échantillons**"""

def view_samples():
    plt.figure(figsize=(10, 10))
    for index in range(25):
        plt.subplot(5, 5, index + 1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        img = np.transpose(images[index], (1, 2, 0))
        plt.imshow(img, cmap=plt.cm.binary)
        plt.xlabel(class_dict[labels[index].item()])
    plt.show()


view_samples()

"""## **Model Training**"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
num_labels = len(class_dict)
print(torch.cuda.is_available())

class CNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3),  # 238 x 238 x 32
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, 32, kernel_size=3),  # 236 x 236 x 32
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.MaxPool2d(kernel_size=2, stride=2), # 118 x 118 x 32
            nn.Conv2d(32, 64, kernel_size=3),  # 116 x 116 x 64
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 64, kernel_size=3),  # 114 x 114 x 64
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.MaxPool2d(kernel_size=2, stride=2), # 57 x 57 x 64
            nn.Conv2d(64, 128, kernel_size=3),  # 55 x 55 x 128
            nn.ReLU(),
            nn.BatchNorm2d(128),
            nn.Conv2d(128, 128, kernel_size=3),  # 53 x 53 x 128
            nn.ReLU(),
            nn.BatchNorm2d(128),
            nn.MaxPool2d(kernel_size=2, stride=2), # 26 x 26 x 128
            nn.Flatten(),
            nn.Linear(in_features=26*26*128, out_features=512),
            nn.ReLU(),
            nn.Linear(512, 2),
        )

    def forward(self, x):
        x = self.layers(x)
        return x


model = CNN()
model.to(device)

"""# **Fonctions d'entraînement et d'évaluation**"""

def train_loop(dataloader, model, loss_fn, optimizer):
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    model.train()
    train_loss, correct = 0, 0
    for batch, (X, y) in enumerate(dataloader):
        X, y = X.float().to(device), y.long().to(device)
        pred = model(X)
        loss = loss_fn(pred, y)

        train_loss += loss.item()
        correct += (pred.argmax(1) == y).type(torch.float).sum().item()
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

        if batch % 10 == 0:
            loss, current = loss.item(), batch * batch_size + len(X)
            print(f"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]")

    average_train_loss = train_loss / num_batches
    train_accuracy = correct / size
    print(f"Training Error: \n Accuracy: {(100*train_accuracy):>0.1f}%, Avg loss: {average_train_loss:>8f} \n")
    return average_train_loss, train_accuracy

def val_loop(dataloader, model, loss_fn):
    model.eval()
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    val_loss, correct = 0, 0

    with torch.no_grad():
        for X, y in dataloader:
            X, y = X.float().to(device), y.long().to(device)
            pred = model(X)
            val_loss += loss_fn(pred, y).item()
            correct += (pred.argmax(1) == y).type(torch.float).sum().item()

    average_val_loss = val_loss / num_batches
    val_accuracy = correct / size
    print(f"Validation Error: \n Accuracy: {(100*val_accuracy):>0.1f}%, Validation loss: {average_val_loss:>8f} \n")
    return average_val_loss, val_accuracy

def evaluate_model(loader, model, loss_fn):
    model.eval()
    y_true = []
    y_pred = []
    total_loss = 0
    correct_examples = []
    incorrect_examples = []
    with torch.no_grad():
        for X, y in loader:
            X, y = X.float().to(device), y.long().to(device)
            outputs = model(X)
            loss = loss_fn(outputs, y)
            total_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            y_true.extend(y.tolist())
            y_pred.extend(predicted.tolist())
            matches = predicted == y
            for i in range(len(matches)):
                example = (X[i].cpu(), y[i].item(), predicted[i].item())
                if matches[i]:
                    correct_examples.append(example)
                else:
                    incorrect_examples.append(example)

    average_loss = total_loss / len(loader)
    accuracy = (np.array(y_true) == np.array(y_pred)).mean()
    return y_true, y_pred, average_loss, accuracy, correct_examples, incorrect_examples

"""# **Intégration du GAN**"""

from torch.optim.lr_scheduler import StepLR  # Ajoutez cette ligne

# Définir le Generator et le Discriminator
class Generator(nn.Module):
    def __init__(self, latent_dim, img_channels, feature_maps):
        super(Generator, self).__init__()
        self.net = nn.Sequential(
            nn.ConvTranspose2d(latent_dim, feature_maps * 8, kernel_size=4, stride=1, padding=0),
            nn.BatchNorm2d(feature_maps * 8),
            nn.ReLU(True),
            nn.ConvTranspose2d(feature_maps * 8, feature_maps * 4, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(feature_maps * 4),
            nn.ReLU(True),
            nn.ConvTranspose2d(feature_maps * 4, feature_maps * 2, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(feature_maps * 2),
            nn.ReLU(True),
            nn.ConvTranspose2d(feature_maps * 2, img_channels, kernel_size=4, stride=2, padding=1),
            nn.Tanh()
        )

    def forward(self, x):
        return self.net(x)

class Discriminator(nn.Module):
    def __init__(self, img_channels, feature_maps):
        super(Discriminator, self).__init__()
        self.net = nn.Sequential(
            nn.Conv2d(img_channels, feature_maps * 2, kernel_size=4, stride=2, padding=1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Dropout(0.3),  # Ajout de Dropout
            nn.Conv2d(feature_maps * 2, feature_maps * 4, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(feature_maps * 4),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Dropout(0.3),  # Ajout de Dropout
            nn.Conv2d(feature_maps * 4, feature_maps * 8, kernel_size=4, stride=2, padding=1),
            nn.BatchNorm2d(feature_maps * 8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Dropout(0.3),  # Ajout de Dropout
            nn.Conv2d(feature_maps * 8, 1, kernel_size=4, stride=1, padding=0),
            nn.AdaptiveAvgPool2d(1),  # Ajout d'une couche de pooling pour réduire la sortie à [batch_size, 1, 1, 1]
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.net(x)
        return x.view(x.size(0), -1)  # Redimensionner la sortie à [batch_size, 1]

# Hyperparamètres pour le GAN
latent_dim = 100
img_channels = 3
feature_maps = 64

# Initialisation du Generator et du Discriminator
generator = Generator(latent_dim, img_channels, feature_maps).to(device)
discriminator = Discriminator(img_channels, feature_maps).to(device)

# Optimiseurs pour le GAN
optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.002, betas=(0.5, 0.999))
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.002, betas=(0.5, 0.999))

# Fonction de perte pour le GAN
criterion = nn.BCELoss()

# Boucle d'entraînement pour le GAN
def train_gan(epoch, dataloader):
    for i, (real_images, _) in enumerate(dataloader):
        real_images = real_images.to(device)
        batch_size = real_images.size(0)

        # Labels réels et faux
        real_labels = torch.ones(batch_size, 1).to(device)
        fake_labels = torch.zeros(batch_size, 1).to(device)

        # Entraînement du Discriminator
        optimizer_D.zero_grad()

        # Forward pass pour les images réelles
        real_outputs = discriminator(real_images)
        d_loss_real = criterion(real_outputs, real_labels)

        # Forward pass pour les images générées
        z = torch.randn(batch_size, latent_dim, 1, 1).to(device)  # Bruit aléatoire
        fake_images = generator(z)
        fake_outputs = discriminator(fake_images.detach())
        d_loss_fake = criterion(fake_outputs, fake_labels)

        # Perte totale du Discriminator
        d_loss = d_loss_real + d_loss_fake
        d_loss.backward()
        optimizer_D.step()

        # Entraînement du Generator
        optimizer_G.zero_grad()

        # Forward pass pour les images générées
        fake_outputs = discriminator(fake_images)
        g_loss = criterion(fake_outputs, real_labels)  # Le Generator essaie de tromper le Discriminator

        # Mise à jour du Generator
        g_loss.backward()
        optimizer_G.step()

        # Affichage des résultats
        if i % 50 == 0:
            print(f"Epoch [{epoch}/{epochs}], Step [{i}/{len(dataloader)}], "
                  f"d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}")

# Définir le learning rate et les fonctions de perte et d'optimisation
learning_rate = 0.001  # Réduire le learning rate
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)
scheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # Plus d'erreur ici

# Listes pour stocker les métriques
train_losses = []
test_losses = []
val_losses = []
train_accs = []
test_accs = []
val_accs = []

# Nombre d'époques
epochs = 30  # Augmenté pour permettre plus de convergence
max_acc = 0
patience = 3
best_val_loss = float('inf')
epochs_without_improvement = 0

# Boucle d'entraînement principale
for t in range(epochs):
    print(f"Epoch {t+1}\n-------------------------------")

    # Exécuter l'entraînement et l'évaluation du modèle principal
    train_loss, train_acc = train_loop(train_loader, model, loss_fn, optimizer)
    val_loss, val_acc = val_loop(val_loader, model, loss_fn)

    # Stocker les valeurs de perte et d'accuracy
    train_losses.append(train_loss)
    train_accs.append(train_acc)
    val_losses.append(val_loss)
    val_accs.append(val_acc)

    # Early stopping
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        epochs_without_improvement = 0
    else:
        epochs_without_improvement += 1
        if epochs_without_improvement >= patience:
            print("Early stopping")
            break

    # Sauvegarde du meilleur modèle
    if val_acc > max_acc:
        print(f"[SAVING] Validation Accuracy Improved ({(100*max_acc):>0.1f}% -> {(100*val_acc):>0.1f}%)")
        max_acc = val_acc
        torch.save(model.state_dict(), "/content/saved_model.pth")
        torch.save(generator.state_dict(), "/content/generator.pth")
        torch.save(discriminator.state_dict(), "/content/discriminator.pth")

    # Ajustement du taux d'apprentissage
    scheduler.step()

    # Entraînement du GAN
    train_gan(t, train_loader)  # Utilisation du train_loader pour le GAN

print("Done!")

"""# **Visualisation des pertes et précisions**"""

plt.figure(figsize=(12, 6))

# Plotting losses
plt.subplot(1, 2, 1)
plt.plot(train_losses, label="Train Loss")
plt.plot(val_losses, label="Validation Loss")
plt.title("Training and Validation Losses")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()

# Plotting accuracies
plt.subplot(1, 2, 2)
plt.plot(train_accs, label="Train Accuracy")
plt.plot(val_accs, label="Validation Accuracy")
plt.title("Training and Validation Accuracies")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()

plt.show()

"""# **Chargement du modèle sauvegardé**"""

model.load_state_dict(torch.load("/content/saved_model.pth"))
model.to(device)

"""# **Évaluation du modèle**"""

loss_fn = torch.nn.CrossEntropyLoss()

y_true, y_pred, test_loss, test_accuracy, correct_examples, incorrect_examples = evaluate_model(test_loader, model, loss_fn)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

print(classification_report(y_true, y_pred))

"""# **Matrice de confusion**"""

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=list(class_dict.values()), yticklabels=list(class_dict.values()))
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

"""# **Affichage des exemples corrects**"""

def display_examples(examples):
    plt.figure(figsize=(10, 10))
    for index, (image, true_label, pred_label) in enumerate(examples[:5]):
        img = image.cpu().numpy().transpose((1, 2, 0))
        plt.subplot(5, 5, index + 1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(img, cmap=plt.cm.binary)
        plt.xlabel(f"True: {class_dict[true_label]}, Pred: {class_dict[pred_label]}")
    plt.show()

display_examples(correct_examples)

"""# **Affichage des exemples incorrects**"""

display_examples(incorrect_examples)

"""# **Affichage des images générées par le Generator**"""

def display_generated_images(generator, latent_dim, n_images=25):
    generator.eval()
    with torch.no_grad():
        z = torch.randn(n_images, latent_dim, 1, 1).to(device)
        generated_images = generator(z).cpu()

    # Normaliser les images dans la plage [0, 1]
    generated_images = (generated_images + 1) / 2  # Transforme [-1, 1] en [0, 1]

    plt.figure(figsize=(10, 10))
    for i in range(n_images):
        plt.subplot(5, 5, i + 1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        img = generated_images[i].numpy().transpose((1, 2, 0))  # Convertir en format HWC
        plt.imshow(img, cmap=plt.cm.binary)
    plt.show()

# Afficher les images générées
display_generated_images(generator, latent_dim)